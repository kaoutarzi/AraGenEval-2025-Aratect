# LMSA at AraGenEval Shared Task: Ensemble-Based Detection of AI-Generated Arabic Text Using Multilingual and Arabic-Specific Models
## Table of Contents
- [Task Description](#task-description)
- [Dataset](#dataset)
- [Approach](#approach)
- [Training](#training)
- [Results](#results)
- [Citation](#citation)

  
 This repository contains the code and resources for our submission to the [AraGenEval 2025 Shared Task](https://ezzini.github.io/AraGenEval/), where our system focuses on detecting AI-generated Arabic text.
Our approach combines multiple multilingual and Arabic-specific pre-trained language models and uses an ensemble voting mechanism for robust performance.
## Task Description
The AraGenEval shared task, part of the ArabicNLP 2025 conference, challenges participants to advance Arabic NLP through three subtasks: authorship style transfer, authorship identification, and AI-generated text detection.
Our work focuses on the **ARATECT** subtask, formulated as a **binary classification** problem: given an Arabic text, the system must determine whether it was authored by a human or generated by a language model.  
## Dataset
The dataset provided by the shared task organizers is **balanced** (50% human, 50% machine) and contains Arabic texts from news articles and literary works.  
- **Training:** 4,798 texts  
- **Development:** 500 texts  
- **Test:** 500 texts  
- Equal class distribution in all splits  
## Approach
We fine-tuned three pre-trained language models:
- **AraBERT** – Arabic-specific BERT variant.
- **XLM-RoBERTa** – Multilingual transformer handling over 100 languages.
- **Fanar** – Arabic-English multimodal LLM developed by QCRI.

These models were trained separately on the ARATECT dataset and combined using a **majority voting ensemble**, leveraging their complementary strengths to achieve balanced performance across metrics.


## Training
`python fanar.py`
`python Arabert.py`
`python XLM-R.py`

### Pretrained Model Checkpoints

Fine-tuned checkpoints for our models are available for download on Kaggle :

- **Fanar** — Fine-tuned checkpoint: https://www.kaggle.com/models/kaoutarzita/finetuned-fanar  
- **XLM-RoBERTa (XLM-R)** — Fine-tuned checkpoint: https://www.kaggle.com/models/kaoutarzita/finetunedxlm-r  
- **AraBERT** — Fine-tuned checkpoint: https://www.kaggle.com/models/kaoutarzita/finetuned-arabert  

These checkpoints correspond to the best-performing models used in our ensemble (described in [Approach](#approach)), and can be loaded directly for inference, evaluation, or further experimentation.


## Results

| Model               | Acc.   | Prec.  | Rec.   | F1     |
|---------------------|--------|--------|--------|--------|
| LR                  | 0.438  | 0.464  | 0.804  | 0.589  |
| MLP                 | 0.506  | 0.503  | 0.988  | 0.667  |
| FusionNet           | 0.578  | 0.552  | 0.824  | 0.661  |
| AraElectra          | 0.688  | 0.737  | 0.584  | 0.652  |
| MARBERT             | 0.586  | 0.563  | 0.764  | 0.649  |
| DeBERTa             | 0.768  | 0.791  | 0.728  | 0.758  |
| Qwen2.5              | 0.480  | 0.490  | 0.940  | 0.644  |
| CAMeL               | 0.642  | 0.612  | 0.776  | 0.684  |
| XLM-R               | 0.832  | 0.911  | 0.736  | 0.814  |
| AraBERT             | 0.864  | 0.882  | 0.840  | 0.861  |
| Fanar               | 0.776  | 0.714  | 0.920  | 0.804  |
| **Majority Voting** | **0.866** | **0.877** | **0.852** | **0.864** |

##  BibTeX Citation
```bibtex
@inproceedings{Zita-anlp-2025,
  title = "{LMSA} at {AraGenEval} shared task: Ensemble-Based Detection of AI-Generated Arabic Text Using Multilingual and Arabic-Specific Models",
  author = "Zita, Kaoutar and Nehar, Attia and Khalil, Abdelkader and Bellaouar, Slimane and Cherroun, Hadda",
  booktitle = "Proceedings of the Third Arabic Natural Language Processing Conference",
  year = "2025",
  address = "Suzhou, China",
  publisher = "Association for Computational Linguistics (ACL)"
}


